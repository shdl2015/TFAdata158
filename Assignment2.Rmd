---
title: "Math 158 Project: Assignment 2"
author: "Sophia Hui and Allison Kirkegaard"
date: "February 19, 2018"
output: pdf_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, fig.height=3, fig.width=5, fig.align = "center")
require(dplyr)
require(ggplot2)
require(infer)
require(skimr)
require(broom)
require(haven)
require(readr)
TFAdata <- read_csv("my_TFAdata.csv")
options(digits=3)
```
##### Introduction

Our data comes from an evaluation of Teach for America conducted by Mathematica Policy Research in 2004, which was designed as a year-long randomized controlled trial including 17 elementary schools from six regions across the United States. It comprises student pre- and posttest scores in math and reading, student survey responses, and teacher survey responses. We chose to have students be our observational units, and merged their teachers' data with their own so that our model of student test performance can include both student and teacher characteristics.

##### Hypothesis Testing

We are introducing a new variable: the difference between pretest and posttest scores in math; the variable will be called 'diff'. We will be testing the linear relationship between 'diff' and the teacher's years of experience. Our explanatory variable will be the student's teacher's total years of teaching experience, and our response variable will be $Y$ = posttest score - pretest score in math. The linear regression model we will be using is $$ Y_i = \beta_0 + \beta_1 X_i + \epsilon_i.$$ Our hypothesis is:

$$ H_0: \beta_1 = 0$$
$$ H_a: \beta_1\neq 0$$

##### Checking Assumptions for Linear Regression

```{r}
TFAdata <- TFAdata %>% mutate(diff = ss_m-press_m)

ggplot(TFAdata, aes(x=a1_a, y=diff)) +
  geom_point() + 
  geom_smooth(method="lm", se=FALSE) +
  labs(x = "Teacher's Total Years of Teaching Experience", y = "Difference in Math Test Scores", title = "Difference in Math Test Scores vs. Teacher's Years of Experience")

test_lm <- lm(diff ~ a1_a, data=TFAdata)
tidy(test_lm)
test_stdres <- broom::augment(test_lm)$.std.resid
plot(fitted(test_lm), test_stdres, ylab="Standardized Residuals", xlab="Predicted Difference in Math Test Scores", main="Residuals of Difference in Math Test Scores vs. Teacher's Experience Model")
abline(0,0)
```

Note that 100 observations were removed because those teachers did not provide how many years of experience they had in teaching. It is possible that those teachers were primarily first-year teachers who thought they had no experience, but since the survey instructed teachers to include the current school year in their total years of teaching experience and thus all teachers should have had at least one year, we chose not to simply recode these missing values as zeros.

Because our explanatory variable is discrete, it is difficult to see a linear relationship between our explanatory and response variables. However, there is no curvilinear relationship evident either, so in the interest of parsimony we will assume that the relationship is linear. 

The residuals from our linear model appear to be normally distributed. Their variance is not quite constant (we see larger residuals associated with higher predicted differences in test scores), so it is important to note that our estimates may be less efficient and our variance estimates may be incorrect.

Our linear model is $$\hat{Y}=12.235 + -0.193X$$, $p < 0.001$. With such a low $p$-value, we can reject $H_0$. 

##### Confidence Interval
```{r}
test_gl <- broom::glance(test_lm)
test_sig <- dplyr::pull(test_gl, sigma)

crit_val <- qt(.975, glance(test_lm)$df.resid)
test_pred <- broom::augment(test_lm) %>%
  mutate(.se.pred = sqrt(test_sig^2 + .se.fit^2)) %>%
  mutate(lower_PI = .fitted - crit_val * .se.pred,
    upper_PI = .fitted + crit_val * .se.pred,
    lower_CI = .fitted - crit_val * .se.fit,
    upper_CI = .fitted + crit_val * .se.fit)
test_pred %>% head()
```
By constructing a 95% prediction interval, we are 95% confident that the difference in pre- and post-test math scores will be in the interval (-15.6, 39.7) for a student who has a teacher with no prior experience ($X_h$ = 1). We also constructed a 95% confidence interval, which tells us that if we were to repeatedly samples, then 95% of our confidence intervals will capture the true mean score difference for students with teachers with 1 year of experience (including the current school year). 

##### Simultaneous Inference
```{r}
# find critical values for Working-Hotelling, Scheffe, and Bonferroni procedures
crit_WH_Sch <- sqrt(2*qf(.95, 2, glance(test_lm)$df.resid))
crit_Bonf <- qt((1-.975)/2, glance(test_lm)$df.resid)

# find mean intervals
test_pred <- test_pred %>%
mutate(lower_CI_WH = .fitted - crit_WH_Sch * .se.fit,
upper_CI_WH = .fitted + crit_WH_Sch * .se.fit,
lower_CI_Bonf = .fitted - crit_Bonf * .se.fit,
upper_CI_Bonf = .fitted + crit_Bonf * .se.fit)
# plot mean intervals
ggplot(test_pred, aes(x = a1_a, y = diff)) + geom_point() +
stat_smooth(method = "lm", se = FALSE) +
geom_ribbon(data = test_pred, aes(ymin = lower_CI, ymax = upper_CI), alpha = .2, fill = "purple") +
geom_ribbon(data = test_pred, aes(ymin = lower_CI_WH, ymax = upper_CI_WH), alpha = .2, fill = "green") +
geom_ribbon(data = test_pred, aes(ymin = lower_CI_Bonf, ymax = upper_CI_Bonf), alpha = .2, fill = "blue") +
labs(x = "Teacher's Total Years of Teaching Experience", y = "Difference in Math Test Scores", title = "Difference in Math Test Scores vs. Teacher's Years of Experience")

# find prediction intervals
test_pred <- test_pred %>%
mutate(lower_PI_Sch = .fitted - crit_WH_Sch * .se.pred,
upper_PI_Sch = .fitted + crit_WH_Sch * .se.pred,
lower_PI_Bonf = .fitted - crit_Bonf * .se.pred,
upper_PI_Bonf = .fitted + crit_Bonf * .se.pred)
# plot prediction intervals
ggplot(test_pred, aes(x = a1_a, y = diff)) + geom_point() +
stat_smooth(method = "lm", se = FALSE) +
geom_ribbon(data = test_pred, aes(ymin = lower_PI, ymax = upper_PI), alpha = .2, fill = "purple") +
geom_ribbon(data = test_pred, aes(ymin = lower_PI_Sch, ymax = upper_PI_Sch), alpha = .2, fill = "green") +
geom_ribbon(data = test_pred, aes(ymin = lower_PI_Bonf, ymax = upper_PI_Bonf), alpha = .2, fill = "blue") +
labs(x = "Teacher's Total Years of Teaching Experience", y = "Difference in Math Test Scores", title = "Difference in Math Test Scores vs. Teacher's Years of Experience")
```

##### Fit of Our Model
A concern about our residuals plot is the non-constant variance. When we look at the residuals around a 12-point difference in math test scores, their magnitudes are larger than the other residuals in the plot. 
```{r}
glance(test_lm)
```
Additionally, our $R^2$ value is very low. Only 0.924% of the variability of the response data is explained by our model. Therefore, our simple linear regression model may not be the best fit for our data.

##### Conclusion
Initially, we were concerned by the scatterplot, because our explanatory variable only had discrete values, which yielded in a plot that did not look linear. However, we were able to reject our null hypothesis and conclude that there was a negative relationship between the total number of years of teaching experience and the difference in math pre- and post-test scores. This surprised us, because typically, more experienced teachers have better success in the classroom. We think this unexpected negative correlation may be a result of teachers' TFA status acting as a confounding variable, since almost all TFA teachers have one or two years of teaching experience and most non-TFA teachers have much more teaching experience. It could be that TFA teachers are more successful in raising student test scores for reasons other than their years of teaching experience, such as their educational backgrounds or the TFA training program. Thus in future assignments, we will want to add other explanatory variables to our model.

